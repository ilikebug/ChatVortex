"use client";

import { useState, useRef, useEffect, forwardRef, useImperativeHandle, useCallback } from "react";
import { motion, AnimatePresence } from "framer-motion";
import { Send, Mic, Square, Sparkles, ChevronLeft, ChevronRight, MicOff, Languages } from "lucide-react";
import { cn } from "@/lib/utils";

interface ChatInputProps {
  onSendMessage: (content: string) => void;
  isLoading?: boolean;
  placeholder?: string;
  onCollapsedChange?: (collapsed: boolean) => void;
  initialCollapsed?: boolean;
}

export interface ChatInputRef {
  focusInput: () => void;
}

export const ChatInput = forwardRef<ChatInputRef, ChatInputProps>(function ChatInput({
  onSendMessage,
  isLoading = false,
  placeholder = "è¾“å…¥æ‚¨çš„æ¶ˆæ¯...",
  onCollapsedChange,
  initialCollapsed = false,
}, ref) {
  const [message, setMessage] = useState("");
  const [isRecording, setIsRecording] = useState(false);
  const [isFocused, setIsFocused] = useState(false);
  const [isCollapsed, setIsCollapsed] = useState(initialCollapsed);
  const [speechSupported, setSpeechSupported] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [speechLang, setSpeechLang] = useState('zh-CN'); // é»˜è®¤ä¸­æ–‡
  const [micLevel, setMicLevel] = useState(0); // éº¦å…‹é£éŸ³é‡çº§åˆ«
  const recognitionRef = useRef<any>(null); // ä½¿ç”¨anyç±»å‹é¿å…TypeScripté”™è¯¯
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);

  // é€šçŸ¥çˆ¶ç»„ä»¶æŠ˜å çŠ¶æ€å˜åŒ–
  const handleCollapsedChange = (collapsed: boolean) => {
    setIsCollapsed(collapsed);
    onCollapsedChange?.(collapsed);
  };
  const textareaRef = useRef<HTMLTextAreaElement>(null);

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
  const initializeSpeechRecognition = useCallback(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      console.log('ğŸ” SpeechRecognition available:', !!SpeechRecognition);
      
      if (SpeechRecognition) {
        setSpeechSupported(true);
        const recognition = new SpeechRecognition();
        recognition.continuous = true; // ä½¿ç”¨è¿ç»­æ¨¡å¼
        recognition.interimResults = true; // å¯ç”¨ä¸´æ—¶ç»“æœ
        recognition.lang = speechLang; // ä½¿ç”¨åŠ¨æ€è¯­è¨€è®¾ç½®
        recognition.maxAlternatives = 1;
        
        console.log('ğŸ¤ Speech recognition initialized with settings:', {
          continuous: recognition.continuous,
          interimResults: recognition.interimResults,
          lang: recognition.lang
        });
        
        recognition.onstart = () => {
          setIsListening(true);
          console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«å¼€å§‹');
        };
        
        recognition.onresult = (event) => {
          console.log('ğŸ¯ Speech recognition result event:', event);
          let finalTranscript = '';
          let interimTranscript = '';
          
          for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript;
            const confidence = event.results[i][0].confidence;
            console.log(`ğŸ“ Result ${i}: "${transcript}" (final: ${event.results[i].isFinal}, confidence: ${confidence})`);
            
            if (event.results[i].isFinal) {
              finalTranscript += transcript;
            } else {
              interimTranscript += transcript;
            }
          }
          
          console.log('ğŸ“Š Transcripts - Interim:', interimTranscript, 'Final:', finalTranscript);
          
          // å®æ—¶æ˜¾ç¤ºä¸´æ—¶ç»“æœ
          if (interimTranscript) {
            console.log('âš¡ Updating with interim result:', interimTranscript);
            setMessage(prev => {
              // ç§»é™¤ä¹‹å‰çš„ä¸´æ—¶æ–‡æœ¬ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
              const cleanPrev = prev.replace(/\s*\[ä¸´æ—¶è¯†åˆ«\].*$/, '');
              return cleanPrev + (cleanPrev ? ' ' : '') + '[ä¸´æ—¶è¯†åˆ«]' + interimTranscript;
            });
          }
          
          if (finalTranscript) {
            console.log('âœ… Processing final result:', finalTranscript);
            // åŸºæœ¬çš„æ ‡ç‚¹ç¬¦å·å¤„ç†
            let processedText = finalTranscript.trim();
            
            // è‹±æ–‡ä¸éœ€è¦ç‰¹æ®Šæ ‡ç‚¹å¤„ç†ï¼Œä¸­æ–‡æ‰éœ€è¦
            if (recognition.lang === 'zh-CN' && processedText && !processedText.match(/[.!?ã€‚ï¼ï¼Ÿ]$/)) {
              // å¦‚æœæ˜¯ç–‘é—®è¯å¼€å¤´ï¼ŒåŠ é—®å·
              if (processedText.match(/^(ä»€ä¹ˆ|æ€ä¹ˆ|ä¸ºä»€ä¹ˆ|å“ªé‡Œ|è°|ä½•æ—¶|å¤šå°‘|å¦‚ä½•)/)) {
                processedText += 'ï¼Ÿ';
              } else {
                processedText += 'ã€‚';
              }
            }
            
            setMessage(prev => {
              // ç§»é™¤ä¸´æ—¶æ ‡è®°æ–‡æœ¬ï¼Œæ·»åŠ æœ€ç»ˆç»“æœ
              const cleanPrev = prev.replace(/\s*\[ä¸´æ—¶è¯†åˆ«\].*$/, '');
              const newMessage = cleanPrev + (cleanPrev ? ' ' : '') + processedText;
              console.log('ğŸ’¬ Final message updated to:', newMessage);
              return newMessage;
            });
            
            // åœ¨è¿ç»­æ¨¡å¼ä¸‹ï¼Œå¤„ç†å®Œæœ€ç»ˆç»“æœåæ¸…ç†ä¸´æ—¶çŠ¶æ€ï¼Œå‡†å¤‡æ¥æ”¶æ–°çš„è¯­éŸ³
            console.log('ğŸ”„ å‡†å¤‡æ¥æ”¶ä¸‹ä¸€æ®µè¯­éŸ³...');
          }
        };
        
        recognition.onerror = (event) => {
          console.error('ğŸš« è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
          
          // æ ¹æ®é”™è¯¯ç±»å‹ç»™å‡ºä¸åŒçš„æç¤ºå’Œå¤„ç†
          if (event.error === 'no-speech') {
            console.log('ğŸ’¡ æç¤º: æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå°è¯•é‡æ–°å¯åŠ¨è¯†åˆ«...');
            // çŸ­æš‚å»¶è¿Ÿåè‡ªåŠ¨é‡å¯ï¼ˆå¦‚æœç”¨æˆ·ä»åœ¨å½•éŸ³çŠ¶æ€ï¼‰
            setTimeout(() => {
              if (isRecording && recognitionRef.current) {
                console.log('ğŸ”„ è‡ªåŠ¨é‡å¯è¯­éŸ³è¯†åˆ«...');
                try {
                  recognitionRef.current.start();
                } catch (error) {
                  console.error('é‡å¯å¤±è´¥:', error);
                  setIsRecording(false);
                  setIsListening(false);
                }
              }
            }, 100);
            return; // ä¸è¦è®¾ç½®åœæ­¢çŠ¶æ€
          } else if (event.error === 'not-allowed') {
            console.error('âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£è®¿é—®');
          } else if (event.error === 'audio-capture') {
            console.error('âŒ æ— æ³•æ•è·éŸ³é¢‘ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦æ­£å¸¸å·¥ä½œ');
          } else {
            console.error('âŒ å…¶ä»–é”™è¯¯:', event.error);
          }
          
          // å¯¹äºé no-speech é”™è¯¯æ‰åœæ­¢å½•éŸ³
          setIsRecording(false);
          setIsListening(false);
          
          // æ¸…ç†ä¸´æ—¶è¯†åˆ«æ–‡æœ¬
          setMessage(prev => prev.replace(/\s*\[ä¸´æ—¶è¯†åˆ«\].*$/, ''));
        };
        
        recognition.onend = () => {
          console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«ç»“æŸ');
          setIsListening(false);
          
          // è¿ç»­æ¨¡å¼ä¸‹å¦‚æœç”¨æˆ·è¿˜åœ¨å½•éŸ³çŠ¶æ€ï¼ŒçŸ­æš‚å»¶è¿Ÿåè‡ªåŠ¨é‡å¯
          if (isRecording && recognitionRef.current) {
            console.log('ğŸ”„ è¿ç»­æ¨¡å¼ï¼šå»¶è¿Ÿ500msåé‡å¯ï¼Œç­‰å¾…æ–°çš„è¯­éŸ³è¾“å…¥...');
            setTimeout(() => {
              if (isRecording && recognitionRef.current) {
                try {
                  setIsListening(true);
                  recognitionRef.current.start();
                  console.log('âœ¨ è¯­éŸ³è¯†åˆ«é‡æ–°å¯åŠ¨ï¼Œç­‰å¾…ä¸‹ä¸€æ®µè¯­éŸ³...');
                } catch (error) {
                  console.error('è¿ç»­é‡å¯å¤±è´¥:', error);
                  setIsRecording(false);
                  setIsListening(false);
                }
              }
            }, 500); // å¢åŠ å»¶è¿Ÿæ—¶é—´ç»™ç”¨æˆ·è¯´è¯çš„é—´éš™
          } else {
            setIsRecording(false);
            
            // æ¸…ç†ä¸´æ—¶è¯†åˆ«æ–‡æœ¬
            setMessage(prev => prev.replace(/\s*\[ä¸´æ—¶è¯†åˆ«\].*$/, ''));
          }
        };
        
        recognitionRef.current = recognition;
      } else {
        setSpeechSupported(false);
        console.warn('âš ï¸ æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½');
      }
    }
    
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
    };
  }, [speechLang]); // å½“è¯­è¨€æ”¹å˜æ—¶é‡æ–°åˆå§‹åŒ–

  // åˆå§‹åŒ–å’Œè¯­è¨€å˜åŒ–æ—¶é‡æ–°åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
  useEffect(() => {
    initializeSpeechRecognition();
  }, [initializeSpeechRecognition]);

  // æš´éœ²focusInputæ–¹æ³•ç»™çˆ¶ç»„ä»¶
  useImperativeHandle(ref, () => ({
    focusInput: () => {
      if (textareaRef.current) {
        textareaRef.current.focus();
        // å¦‚æœå½“å‰æ˜¯æŠ˜å çŠ¶æ€ï¼Œåˆ™å±•å¼€
        if (isCollapsed) {
          handleCollapsedChange(false);
        }
      }
    }
  }), [isCollapsed, handleCollapsedChange]);

  // è‡ªåŠ¨è°ƒæ•´æ–‡æœ¬æ¡†é«˜åº¦
  useEffect(() => {
    const textarea = textareaRef.current;
    if (textarea && !isCollapsed) {
      textarea.style.height = "auto";
      textarea.style.height = `${Math.min(textarea.scrollHeight, 120)}px`;
    }
  }, [message, isCollapsed]);

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    if (message.trim() && !isLoading) {
      onSendMessage(message.trim());
      setMessage("");
    }
  };

  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSubmit(e);
    }
  };

  // åˆ‡æ¢è¯­éŸ³è¯†åˆ«è¯­è¨€
  const toggleSpeechLanguage = () => {
    const newLang = speechLang === 'zh-CN' ? 'en-US' : 'zh-CN';
    setSpeechLang(newLang);
    console.log('ğŸŒ è¯­éŸ³è¯†åˆ«è¯­è¨€åˆ‡æ¢ä¸º:', newLang === 'zh-CN' ? 'ä¸­æ–‡' : 'è‹±æ–‡');
  };

  // å¯åŠ¨éº¦å…‹é£éŸ³é‡ç›‘æµ‹
  const startMicrophoneMonitoring = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 256;
      microphone.connect(analyser);
      
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;
      
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      
      const updateLevel = () => {
        if (!analyserRef.current || !isRecording) return;
        
        analyser.getByteFrequencyData(dataArray);
        const sum = dataArray.reduce((a, value) => a + value, 0);
        const average = sum / dataArray.length;
        const level = Math.min(100, Math.round(average));
        
        setMicLevel(level);
        console.log('ğŸµ éº¦å…‹é£éŸ³é‡çº§åˆ«:', level);
        
        if (isRecording) {
          requestAnimationFrame(updateLevel);
        }
      };
      
      updateLevel();
      return stream;
    } catch (error) {
      console.error('âŒ éº¦å…‹é£ç›‘æµ‹å¯åŠ¨å¤±è´¥:', error);
      return null;
    }
  };

  // æ£€æŸ¥éº¦å…‹é£æƒé™
  const checkMicrophonePermission = async () => {
    try {
      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log('ğŸ¤ éº¦å…‹é£æƒé™æ£€æŸ¥é€šè¿‡');
        stream.getTracks().forEach(track => track.stop()); // é‡Šæ”¾èµ„æº
        return true;
      }
    } catch (error) {
      console.error('âŒ éº¦å…‹é£æƒé™æ£€æŸ¥å¤±è´¥:', error);
      return false;
    }
    return false;
  };

  const toggleRecording = async () => {
    console.log('ğŸ™ï¸ Toggle recording called. Current state:', { 
      speechSupported, 
      hasRecognition: !!recognitionRef.current, 
      isRecording, 
      isListening 
    });
    
    if (!speechSupported || !recognitionRef.current) {
      console.warn('âš ï¸ è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨');
      return;
    }

    if (isRecording || isListening) {
      console.log('ğŸ›‘ Stopping speech recognition...');
      // åœæ­¢å½•éŸ³
      recognitionRef.current.stop();
      setIsRecording(false);
      
      // æ¸…ç†ä¸´æ—¶è¯†åˆ«æ–‡æœ¬
      setTimeout(() => {
        setMessage(prev => prev.replace(/\s*\[ä¸´æ—¶è¯†åˆ«\].*$/, ''));
      }, 100);
    } else {
      // å¼€å§‹å½•éŸ³å‰å…ˆæ£€æŸ¥éº¦å…‹é£æƒé™
      console.log('ğŸ” æ£€æŸ¥éº¦å…‹é£æƒé™...');
      const hasPermission = await checkMicrophonePermission();
      
      if (!hasPermission) {
        console.error('âŒ éº¦å…‹é£æƒé™ä¸è¶³ï¼Œè¯·å…è®¸æµè§ˆå™¨è®¿é—®éº¦å…‹é£');
        return;
      }
      
      console.log('ğŸ¬ Starting speech recognition...');
      try {
        setIsRecording(true);
        
        // å¯åŠ¨éº¦å…‹é£ç›‘æµ‹
        await startMicrophoneMonitoring();
        
        recognitionRef.current.start();
        console.log('âœ… Speech recognition started successfully');
      } catch (error) {
        console.error('ğŸš« è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥:', error);
        setIsRecording(false);
      }
    }
  };

  if (isCollapsed) {
    return (
      <div className="flex justify-start w-full">
        <motion.button
          initial={{ opacity: 0, scale: 0.8, x: -50 }}
          animate={{ 
            opacity: 1, 
            scale: 1, 
            x: 0,
            boxShadow: "0 8px 20px rgba(99, 102, 241, 0.25)"
          }}
          transition={{ 
            duration: 0.4,
            ease: [0.23, 1, 0.32, 1],
            delay: 0.05
          }}
          type="button"
          onClick={() => handleCollapsedChange(false)}
          className="flex items-center justify-center w-12 h-16 bg-gradient-to-t from-indigo-500 to-indigo-600 hover:from-indigo-600 hover:to-indigo-700 text-white rounded-xl shadow-lg hover:shadow-xl transition-all duration-200 relative overflow-hidden"
          whileHover={{ 
            scale: 1.05, 
            x: 5,
            boxShadow: "0 15px 35px rgba(99, 102, 241, 0.4)",
            transition: { duration: 0.2 }
          }}
          whileTap={{ 
            scale: 0.95,
            transition: { duration: 0.1 }
          }}
        >
          {/* å…‰æ•ˆèƒŒæ™¯ */}
          <motion.div
            className="absolute inset-0 bg-gradient-to-r from-white/0 via-white/20 to-white/0"
            initial={{ x: "-100%" }}
            animate={{ x: "100%" }}
            transition={{ 
              duration: 2, 
              repeat: Infinity, 
              repeatDelay: 3,
              ease: "linear"
            }}
          />
          
          <motion.div
            animate={{ 
              x: [0, 2, 0],
              transition: { duration: 1.5, repeat: Infinity, ease: "easeInOut" }
            }}
          >
            <ChevronRight size={20} />
          </motion.div>
        </motion.button>
      </div>
    );
  }

  return (
    <motion.div
      initial={{ opacity: 0, scale: 0.95 }}
      animate={{ 
        opacity: 1, 
        scale: 1,
        transition: {
          duration: 0.3,
          ease: [0.23, 1, 0.32, 1]
        }
      }}
      exit={{
        opacity: 0,
        scale: 0.95,
        transition: { duration: 0.2 }
      }}
      className="w-full"
    >
      <div className="relative">
        {/* å¤–éƒ¨æ§åˆ¶æŒ‰é’® */}
        <div className="flex items-center gap-2 mb-2 relative">
          {/* æŠ˜å æŒ‰é’® */}
          <motion.button
            type="button"
            onClick={() => handleCollapsedChange(true)}
            className="flex-shrink-0 p-2 rounded-lg bg-gray-100 hover:bg-gray-200 text-gray-500 hover:text-gray-700 transition-all duration-200"
            whileHover={{ 
              scale: 1.05,
              transition: { duration: 0.2 }
            }}
            whileTap={{ 
              scale: 0.95,
              transition: { duration: 0.1 }
            }}
            title="æŠ˜å è¾“å…¥æ¡†"
          >
            <ChevronLeft size={16} />
          </motion.button>

          {/* è¯­è¨€åˆ‡æ¢æŒ‰é’® */}
          {speechSupported && (
            <motion.button
              type="button"
              onClick={toggleSpeechLanguage}
              disabled={isLoading || isRecording || isListening}
              whileHover={{ 
                scale: 1.05,
                transition: { duration: 0.2 }
              }}
              whileTap={{ scale: 0.95 }}
              className={cn(
                "p-2 rounded-lg transition-all duration-200 text-xs font-medium",
                isRecording || isListening
                  ? "bg-gray-200 text-gray-400 cursor-not-allowed"
                  : "bg-indigo-100 hover:bg-indigo-200 text-indigo-700"
              )}
              title={`åˆ‡æ¢åˆ°${speechLang === 'zh-CN' ? 'è‹±æ–‡' : 'ä¸­æ–‡'}è¯†åˆ«`}
            >
              {speechLang === 'zh-CN' ? 'ä¸­' : 'EN'}
            </motion.button>
          )}

          {/* è¯­éŸ³æŒ‰é’® */}
          <motion.button
            type="button"
            onClick={toggleRecording}
            disabled={!speechSupported || isLoading}
            whileHover={speechSupported ? { 
              scale: 1.05,
              rotate: isRecording ? 0 : 5,
              transition: { duration: 0.2 }
            } : {}}
            whileTap={speechSupported ? { scale: 0.95 } : {}}
            className={cn(
              "p-2 rounded-lg transition-all duration-200 relative overflow-hidden",
              !speechSupported
                ? "bg-gray-100 text-gray-400 cursor-not-allowed opacity-50"
                : isRecording || isListening
                ? "bg-red-500 text-white shadow-lg shadow-red-200"
                : "bg-gray-100 hover:bg-gray-200 text-gray-600"
            )}
            title={
              !speechSupported 
                ? "æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½"
                : isRecording || isListening 
                ? "ç‚¹å‡»åœæ­¢å½•éŸ³" 
                : `ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥ (${speechLang === 'zh-CN' ? 'ä¸­æ–‡' : 'è‹±æ–‡'})`
            }
          >
            {isRecording && (
              <motion.div
                className="absolute inset-0 bg-red-400/30 rounded-lg"
                animate={{
                  scale: [1, 1.1, 1],
                  opacity: [0.3, 0.6, 0.3]
                }}
                transition={{
                  duration: 1,
                  repeat: Infinity,
                  ease: "easeInOut"
                }}
              />
            )}
            <AnimatePresence mode="wait">
              {!speechSupported ? (
                <motion.div
                  key="disabled"
                  initial={{ scale: 0 }}
                  animate={{ scale: 1 }}
                  exit={{ scale: 0 }}
                >
                  <MicOff size={16} />
                </motion.div>
              ) : isRecording || isListening ? (
                <motion.div
                  key="recording"
                  initial={{ scale: 0 }}
                  animate={{ scale: 1 }}
                  exit={{ scale: 0 }}
                >
                  <Square size={16} />
                </motion.div>
              ) : (
                <motion.div
                  key="mic"
                  initial={{ scale: 0 }}
                  animate={{ scale: 1 }}
                  exit={{ scale: 0 }}
                >
                  <Mic size={16} />
                </motion.div>
              )}
            </AnimatePresence>
          </motion.button>

          {/* è¯­éŸ³çŠ¶æ€æŒ‡ç¤ºå™¨ - ç´§è´´è¯­éŸ³æŒ‰é’®å³ä¾§ */}
          {(isRecording || isListening) && (
            <motion.div
              className="flex items-center"
              initial={{ opacity: 0, x: -10 }}
              animate={{ opacity: 1, x: 0 }}
              exit={{ opacity: 0, x: -10 }}
            >
              <div className="bg-red-500 text-white px-3 py-1 rounded-full text-xs flex items-center gap-2 shadow-lg">
                <motion.div
                  className="w-2 h-2 bg-white rounded-full"
                  animate={{
                    scale: [1, 1.3, 1],
                    opacity: [1, 0.7, 1]
                  }}
                  transition={{
                    duration: 1,
                    repeat: Infinity,
                    ease: "easeInOut"
                  }}
                />
                {isListening ? "æ­£åœ¨å½•éŸ³..." : "ç­‰å¾…è¯­éŸ³..."}
                {micLevel > 0 && (
                  <span className="text-xs opacity-80">
                    ğŸµ{micLevel}
                  </span>
                )}
                <span className="text-xs opacity-60">
                  ({speechLang === 'zh-CN' ? 'ä¸­æ–‡' : 'è‹±æ–‡'})
                </span>
              </div>
            </motion.div>
          )}
        </div>

        <form onSubmit={handleSubmit} className="relative">
          <motion.div 
            className="flex items-stretch rounded-2xl border border-gray-200 bg-white shadow-sm relative overflow-hidden"
            whileHover={{
              boxShadow: "0 8px 25px rgba(0, 0, 0, 0.12)",
              borderColor: "rgb(165, 180, 252)",
              transition: { duration: 0.2 }
            }}
          >
            {/* åŠ¨æ€è¾¹æ¡†å…‰æ•ˆ */}
            <motion.div
              className="absolute inset-0 rounded-2xl"
              style={{
                background: "linear-gradient(90deg, transparent, rgba(99, 102, 241, 0.1), transparent)",
                backgroundSize: "200% 100%"
              }}
              animate={{
                backgroundPosition: ["0% 50%", "200% 50%", "0% 50%"]
              }}
              transition={{
                duration: 3,
                repeat: Infinity,
                ease: "linear"
              }}
            />

            {/* è¾“å…¥åŒºåŸŸ */}
            <div className="flex-1 flex items-end gap-3 p-4 relative z-10">
            {/* æ–‡æœ¬è¾“å…¥ */}
            <motion.div 
              className="flex-1 relative"
              animate={{
                scale: isFocused ? 1.02 : 1,
                transition: { duration: 0.2 }
              }}
            >
              <motion.textarea
                ref={textareaRef}
                value={message}
                onChange={(e) => setMessage(e.target.value)}
                onKeyDown={handleKeyDown}
                onFocus={() => setIsFocused(true)}
                onBlur={() => setIsFocused(false)}
                placeholder={placeholder}
                rows={1}
                disabled={isLoading}
                className="w-full bg-transparent border-0 outline-none resize-none text-gray-800 placeholder:text-gray-400 text-sm leading-relaxed py-2 px-0 max-h-[120px] overflow-y-auto transition-all duration-200"
                style={{
                  scrollbarWidth: "thin",
                  scrollbarColor: "#cbd5e1 transparent",
                }}
                whileFocus={{
                  scale: 1.01,
                  transition: { duration: 0.2 }
                }}
              />

              {/* å­—ç¬¦è®¡æ•° */}
              <AnimatePresence>
                {message.length > 0 && (
                  <motion.div
                    initial={{ opacity: 0, scale: 0.8 }}
                    animate={{ opacity: 1, scale: 1 }}
                    exit={{ opacity: 0, scale: 0.8 }}
                    className="absolute bottom-1 right-1 text-xs text-gray-400"
                  >
                    {message.length}
                  </motion.div>
                )}
              </AnimatePresence>
            </motion.div>


            {/* å‘é€æŒ‰é’® */}
            <motion.button
              type="submit"
              disabled={!message.trim() || isLoading}
              whileHover={{ 
                scale: message.trim() ? 1.05 : 1,
                boxShadow: message.trim() 
                  ? "0 10px 25px rgba(99, 102, 241, 0.3)" 
                  : "none",
                transition: { duration: 0.2 }
              }}
              whileTap={{ scale: message.trim() ? 0.95 : 1 }}
              className={cn(
                "p-3 rounded-xl transition-all duration-200 relative overflow-hidden",
                message.trim() && !isLoading
                  ? "bg-indigo-500 hover:bg-indigo-600 text-white shadow-lg shadow-indigo-200"
                  : "bg-gray-200 text-gray-400 cursor-not-allowed"
              )}
            >
              {/* å‘é€æŒ‰é’®å…‰æ•ˆ */}
              {message.trim() && !isLoading && (
                <motion.div
                  className="absolute inset-0 bg-gradient-to-r from-white/0 via-white/20 to-white/0"
                  initial={{ x: "-100%" }}
                  animate={{ x: "100%" }}
                  transition={{ 
                    duration: 1.5, 
                    repeat: Infinity, 
                    repeatDelay: 2,
                    ease: "linear"
                  }}
                />
              )}
              <AnimatePresence mode="wait">
                {isLoading ? (
                  <motion.div
                    key="loading-spinner"
                    initial={{ opacity: 0, scale: 0.8 }}
                    animate={{ opacity: 1, scale: 1, rotate: 360 }}
                    exit={{ opacity: 0, scale: 0.8 }}
                    transition={{
                      rotate: {
                        duration: 1,
                        repeat: Infinity,
                        ease: "linear",
                      },
                      opacity: { duration: 0.2 },
                      scale: { duration: 0.2 },
                    }}
                  >
                    <Sparkles size={16} />
                  </motion.div>
                ) : (
                  <motion.div
                    key="send-icon"
                    initial={{ opacity: 0, scale: 0.8 }}
                    animate={{ opacity: 1, scale: 1 }}
                    exit={{ opacity: 0, scale: 0.8 }}
                    transition={{ duration: 0.2 }}
                  >
                    <Send size={16} />
                  </motion.div>
                )}
              </AnimatePresence>
            </motion.button>
          </div>
        </motion.div>
      </form>
      </div>
    </motion.div>
  );
});